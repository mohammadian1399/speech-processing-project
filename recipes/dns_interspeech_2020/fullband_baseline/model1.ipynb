{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObJiBdYcHNeoX4UfmIk7m0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"1aXL1DBrXpNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628071023104,"user_tz":-270,"elapsed":14,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}},"outputId":"12abbdb0-44ce-4a80-baec-c78b9f963063"},"source":["import torch\n","from torch.nn import functional\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","% cd gdrive/MyDrive/'Colab Notebooks'/FullSubNet\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","[Errno 2] No such file or directory: 'gdrive/MyDrive/Colab Notebooks/FullSubNet'\n","/content/gdrive/MyDrive/Colab Notebooks/FullSubNet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBH2-hJROtxY","executionInfo":{"status":"ok","timestamp":1628071026612,"user_tz":-270,"elapsed":380,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}},"outputId":"b80c6ec4-44a2-4270-92a6-596b5fbb8f62"},"source":["!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["audio_zen  data  docs  __init__.py  recipes  tools\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYS76Q1gPL3E","executionInfo":{"status":"ok","timestamp":1628071030210,"user_tz":-270,"elapsed":8,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}},"outputId":"db176338-6e7a-4e73-eb45-c83d2851e037"},"source":["% cd /content/gdrive/MyDrive/Colab Notebooks/FullSubNet/audio_zen"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/FullSubNet/audio_zen\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U-8CWlT7Peh1","executionInfo":{"status":"ok","timestamp":1628071032511,"user_tz":-270,"elapsed":373,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["# import audio_zen\n","# %cd /content/gdrive/MyDrive/Colab Notebooks/FullSubNet/audio_zen/model\n","# import model\n","# from model import module\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAZeUAGFR-Uo","executionInfo":{"status":"ok","timestamp":1628071034963,"user_tz":-270,"elapsed":378,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["# import os\n","\n","# # change the current working directory\n","# # to specified path\n","# #os.chdir('c:\\\\gfg_dir')\n","\n","# # varify the path using getcwd()\n","# cwd = os.getcwd()\n","\n","# # print the current directory\n","# print(\"Current working directory is:\", cwd)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMvUFyc9Oop_","executionInfo":{"status":"ok","timestamp":1628071036797,"user_tz":-270,"elapsed":4,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["# from audio_zen.model.base_model import BaseModel\n","\n","# from audio_zen.model.module.sequence_model import SequenceModel"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ax2zg_UfkoBQ"},"source":["### base_model:"]},{"cell_type":"code","metadata":{"id":"rZ8Id4cwkzX0","executionInfo":{"status":"ok","timestamp":1628071308261,"user_tz":-270,"elapsed":1012,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["# base_model.ipynb\n","import torch.nn as nn\n","import torch.nn.init as init\n","import numpy as np\n","EPSILON = np.finfo(np.float32).eps\n","\n","class BaseModel(nn.Module):\n","    def __init__(self):\n","        super(BaseModel, self).__init__()\n","\n","    @staticmethod\n","    def unfold(input, num_neighbor):\n","        \"\"\"\n","        Along with the frequency dim, split overlapped sub band units from spectrogram.\n","\n","        Args:\n","            input: [B, C, F, T]\n","            num_neighbor:\n","\n","        Returns:\n","            [B, N, C, F_s, T], F is the size of the frequency axis of the sub-band, e.g. [2, 161, 1, 19, 200]\n","        \"\"\"\n","        assert input.dim() == 4, f\"The dim of input is {input.dim()}. It should be four dim.\"\n","        batch_size, num_channels, num_freqs, num_frames = input.size()\n","\n","        if num_neighbor < 1:\n","            # No change for the input\n","            return input.permute(0, 2, 1, 3).reshape(batch_size, num_freqs, num_channels, 1, num_frames)\n","\n","        output = input.reshape(batch_size * num_channels, 1, num_freqs, num_frames)\n","        sub_band_unit_size = num_neighbor * 2 + 1\n","\n","        # Pad to the top and bottom\n","        output = functional.pad(output, [0, 0, num_neighbor, num_neighbor], mode=\"reflect\")\n","\n","        output = functional.unfold(output, (sub_band_unit_size, num_frames))\n","        assert output.shape[-1] == num_freqs, f\"n_freqs != N (sub_band), {num_freqs} != {output.shape[-1]}\"\n","\n","        # Split the dim of the unfolded feature\n","        output = output.reshape(batch_size, num_channels, sub_band_unit_size, num_frames, num_freqs)\n","        output = output.permute(0, 4, 1, 2, 3).contiguous()\n","\n","        return output\n","\n","    @staticmethod\n","    def _reduce_complexity_separately(sub_band_input, full_band_output, device):\n","        \"\"\"\n","\n","        Args:\n","            sub_band_input: [60, 257, 1, 33, 200]\n","            full_band_output: [60, 257, 1, 3, 200]\n","            device:\n","\n","        Notes:\n","            1. 255 and 256 freq not able to be trained\n","            2. batch size should be divisible by 3, otherwise the frequency in the last part of the batch will not be well trained\n","\n","        Returns:\n","            [60, 85, 1, 36, 200]\n","        \"\"\"\n","        batch_size = full_band_output.shape[0]\n","        n_freqs = full_band_output.shape[1]\n","        sub_batch_size = batch_size // 3\n","        final_selected = []\n","\n","        for idx in range(3):\n","            # [0, 60) => [0, 20)\n","            sub_batch_indices = torch.arange(idx * sub_batch_size, (idx + 1) * sub_batch_size, device=device)\n","            full_band_output_sub_batch = torch.index_select(full_band_output, dim=0, index=sub_batch_indices)\n","            sub_band_output_sub_batch = torch.index_select(sub_band_input, dim=0, index=sub_batch_indices)\n","\n","            # Avoid to use padded value (first freq and last freq)\n","            # i = 0, (1, 256, 3) = [1, 4, ..., 253]\n","            # i = 1, (2, 256, 3) = [2, 5, ..., 254]\n","            # i = 2, (3, 256, 3) = [3, 6, ..., 255]\n","            freq_indices = torch.arange(idx + 1, n_freqs - 1, step=3, device=device)\n","            full_band_output_sub_batch = torch.index_select(full_band_output_sub_batch, dim=1, index=freq_indices)\n","            sub_band_output_sub_batch = torch.index_select(sub_band_output_sub_batch, dim=1, index=freq_indices)\n","\n","            # ([30, 85, 1, 33 200], [30, 85, 1, 3, 200]) => [30, 85, 1, 36, 200]\n","\n","            final_selected.append(torch.cat([sub_band_output_sub_batch, full_band_output_sub_batch], dim=-2))\n","\n","        return torch.cat(final_selected, dim=0)\n","\n","    @staticmethod\n","    def sband_forgetting_norm(input, train_sample_length):\n","        \"\"\"\n","        Same as forgetting norm, but use the middle frequency band of the spliced model to calculate the mean ineffective\n","        Args:\n","            input:\n","            train_sample_length:\n","\n","        Returns:\n","\n","        \"\"\"\n","        assert input.ndim == 3\n","        batch_size, n_freqs, n_frames = input.size()\n","\n","        eps = 1e-10\n","        alpha = (train_sample_length - 1) / (train_sample_length + 1)\n","        mu = 0\n","        mu_list = []\n","\n","        for idx in range(input.shape[-1]):\n","            if idx < train_sample_length:\n","                alp = torch.min(torch.tensor([(idx - 1) / (idx + 1), alpha]))\n","                mu = alp * mu + (1 - alp) * torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","            else:\n","                mu = alpha * mu + (1 - alpha) * input[:, (n_freqs // 2 - 1), idx].reshape(batch_size, 1)\n","\n","            mu_list.append(mu)\n","\n","            # print(\"input\", input[:, :, idx].min(), input[:, :, idx].max(), input[:, :, idx].mean())\n","            # print(f\"alp {idx}: \", alp)\n","            # print(f\"mu {idx}: {mu[128, 0]}\")\n","\n","        mu = torch.stack(mu_list, dim=-1)  # [B, 1, T]\n","        input = input / (mu + eps)\n","        return input\n","\n","    @staticmethod\n","    def forgetting_norm(input, sample_length_in_training):\n","        \"\"\"\n","        The input is three-dimensional, and the mean value of the current norm is used as the mean value of the current norm by constantly estimating the mean value of the neighboring\n","\n","        Args:\n","            input: [B, F, T]\n","            sample_length_in_training: The length of training, used to calculate the smoothing factor\n","\n","        Returns:\n","\n","        \"\"\"\n","        assert input.ndim == 3\n","        batch_size, n_freqs, n_frames = input.size()\n","        eps = 1e-10\n","        mu = 0\n","        alpha = (sample_length_in_training - 1) / (sample_length_in_training + 1)\n","\n","        mu_list = []\n","        for idx in range(input.shape[-1]):\n","            if idx < sample_length_in_training:\n","                alp = torch.min(torch.tensor([(idx - 1) / (idx + 1), alpha]))\n","                mu = alp * mu + (1 - alp) * torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","            else:\n","                current_frame_mu = torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","                mu = alpha * mu + (1 - alpha) * current_frame_mu\n","\n","            mu_list.append(mu)\n","\n","            # print(\"input\", input[:, :, idx].min(), input[:, :, idx].max(), input[:, :, idx].mean())\n","            # print(f\"alp {idx}: \", alp)\n","            # print(f\"mu {idx}: {mu[128, 0]}\")\n","\n","        mu = torch.stack(mu_list, dim=-1)  # [B, 1, T]\n","        input = input / (mu + eps)\n","        return input\n","\n","    @staticmethod\n","    def hybrid_norm(input, sample_length_in_training=192):\n","        \"\"\"\n","        Args:\n","            input: [B, F, T]\n","            sample_length_in_training:\n","\n","        Returns:\n","            [B, F, T]\n","        \"\"\"\n","        assert input.ndim == 3\n","        device = input.device\n","        data_type = input.dtype\n","        batch_size, n_freqs, n_frames = input.size()\n","        eps = 1e-10\n","\n","        mu = 0\n","        alpha = (sample_length_in_training - 1) / (sample_length_in_training + 1)\n","        mu_list = []\n","        for idx in range(input.shape[-1]):\n","            if idx < sample_length_in_training:\n","                alp = torch.min(torch.tensor([(idx - 1) / (idx + 1), alpha]))\n","                mu = alp * mu + (1 - alp) * torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","                mu_list.append(mu)\n","            else:\n","                break\n","        initial_mu = torch.stack(mu_list, dim=-1)  # [B, 1, T]\n","\n","        step_sum = torch.sum(input, dim=1)  # [B, T]\n","        cumulative_sum = torch.cumsum(step_sum, dim=-1)  # [B, T]\n","\n","        entry_count = torch.arange(n_freqs, n_freqs * n_frames + 1, n_freqs, dtype=data_type, device=device)\n","        entry_count = entry_count.reshape(1, n_frames)  # [1, T]\n","        entry_count = entry_count.expand_as(cumulative_sum)  # [1, T] => [B, T]\n","\n","        cum_mean = cumulative_sum / entry_count  # B, T\n","\n","        cum_mean = cum_mean.reshape(batch_size, 1, n_frames)  # [B, 1, T]\n","\n","        # print(initial_mu[0, 0, :50])\n","        # print(\"-\"*60)\n","        # print(cum_mean[0, 0, :50])\n","        cum_mean[:, :, :sample_length_in_training] = initial_mu\n","\n","        return input / (cum_mean + eps)\n","\n","    @staticmethod\n","    def offline_laplace_norm(input):\n","        \"\"\"\n","\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","            [B, C, F, T]\n","        \"\"\"\n","        # utterance-level mu\n","        mu = torch.mean(input, dim=(1, 2, 3), keepdim=True)\n","\n","        normed = input / (mu + 1e-5)\n","\n","        return normed\n","\n","    @staticmethod\n","    def cumulative_laplace_norm(input):\n","        \"\"\"\n","\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","\n","        \"\"\"\n","        batch_size, num_channels, num_freqs, num_frames = input.size()\n","        input = input.reshape(batch_size * num_channels, num_freqs, num_frames)\n","\n","        step_sum = torch.sum(input, dim=1)  # [B * C, F, T] => [B, T]\n","        cumulative_sum = torch.cumsum(step_sum, dim=-1)  # [B, T]\n","\n","        entry_count = torch.arange(\n","            num_freqs,\n","            num_freqs * num_frames + 1,\n","            num_freqs,\n","            dtype=input.dtype,\n","            device=input.device\n","        )\n","        entry_count = entry_count.reshape(1, num_frames)  # [1, T]\n","        entry_count = entry_count.expand_as(cumulative_sum)  # [1, T] => [B, T]\n","\n","        cumulative_mean = cumulative_sum / entry_count  # B, T\n","        cumulative_mean = cumulative_mean.reshape(batch_size * num_channels, 1, num_frames)\n","\n","        normed = input / (cumulative_mean + EPSILON)\n","\n","        return normed.reshape(batch_size, num_channels, num_freqs, num_frames)\n","\n","    @staticmethod\n","    def offline_gaussian_norm(input):\n","        \"\"\"\n","        Zero-Norm\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","            [B, C, F, T]\n","        \"\"\"\n","        mu = torch.mean(input, dim=(1, 2, 3), keepdim=True)\n","        std = torch.std(input, dim=(1, 2, 3), keepdim=True)\n","\n","        normed = (input - mu) / (std + 1e-5)\n","\n","        return normed\n","\n","    @staticmethod\n","    def cumulative_layer_norm(input):\n","        \"\"\"\n","        Online zero-norm\n","\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","            [B, C, F, T]\n","        \"\"\"\n","        batch_size, num_channels, num_freqs, num_frames = input.size()\n","        input = input.reshape(batch_size * num_channels, num_freqs, num_frames)\n","\n","        step_sum = torch.sum(input, dim=1)  # [B * C, F, T] => [B, T]\n","        step_pow_sum = torch.sum(torch.square(input), dim=1)\n","\n","        cumulative_sum = torch.cumsum(step_sum, dim=-1)  # [B, T]\n","        cumulative_pow_sum = torch.cumsum(step_pow_sum, dim=-1)  # [B, T]\n","\n","        entry_count = torch.arange(\n","            num_freqs,\n","            num_freqs * num_frames + 1,\n","            num_freqs,\n","            dtype=input.dtype,\n","            device=input.device\n","        )\n","        entry_count = entry_count.reshape(1, num_frames)  # [1, T]\n","        entry_count = entry_count.expand_as(cumulative_sum)  # [1, T] => [B, T]\n","\n","        cumulative_mean = cumulative_sum / entry_count  # [B, T]\n","        cumulative_var = (cumulative_pow_sum - 2 * cumulative_mean * cumulative_sum) / entry_count + cumulative_mean.pow(2)  # [B, T]\n","        cumulative_std = torch.sqrt(cumulative_var + EPSILON)  # [B, T]\n","\n","        cumulative_mean = cumulative_mean.reshape(batch_size * num_channels, 1, num_frames)\n","        cumulative_std = cumulative_std.reshape(batch_size * num_channels, 1, num_frames)\n","\n","        normed = (input - cumulative_mean) / cumulative_std\n","\n","        return normed.reshape(batch_size, num_channels, num_freqs, num_frames)\n","\n","    def norm_wrapper(self, norm_type: str):\n","        if norm_type == \"offline_laplace_norm\":\n","            norm = self.offline_laplace_norm\n","        elif norm_type == \"cumulative_laplace_norm\":\n","            norm = self.cumulative_laplace_norm\n","        elif norm_type == \"offline_gaussian_norm\":\n","            norm = self.offline_gaussian_norm\n","        elif norm_type == \"cumulative_layer_norm\":\n","            norm = self.cumulative_layer_norm\n","        else:\n","            raise NotImplementedError(\"You must set up a type of Norm. \"\n","                                      \"e.g. offline_laplace_norm, cumulative_laplace_norm, forgetting_norm, etc.\")\n","        return norm\n","\n","    def weight_init(self, m):\n","        \"\"\"\n","        Usage:\n","            model = Model()\n","            model.apply(weight_init)\n","        \"\"\"\n","        if isinstance(m, nn.Conv1d):\n","            init.normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.Conv2d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.Conv3d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.ConvTranspose1d):\n","            init.normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.ConvTranspose2d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.ConvTranspose3d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.BatchNorm1d):\n","            init.normal_(m.weight.data, mean=1, std=0.02)\n","            init.constant_(m.bias.data, 0)\n","        elif isinstance(m, nn.BatchNorm2d):\n","            init.normal_(m.weight.data, mean=1, std=0.02)\n","            init.constant_(m.bias.data, 0)\n","        elif isinstance(m, nn.BatchNorm3d):\n","            init.normal_(m.weight.data, mean=1, std=0.02)\n","            init.constant_(m.bias.data, 0)\n","        elif isinstance(m, nn.Linear):\n","            init.xavier_normal_(m.weight.data)\n","            init.normal_(m.bias.data)\n","        elif isinstance(m, nn.LSTM):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n","        elif isinstance(m, nn.LSTMCell):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n","        elif isinstance(m, nn.GRU):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n","        elif isinstance(m, nn.GRUCell):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2JmpFLdwlH2S"},"source":["### sequence_model:"]},{"cell_type":"code","metadata":{"id":"jxyDOGNLlXPN","executionInfo":{"status":"ok","timestamp":1628071329410,"user_tz":-270,"elapsed":395,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["#sequence_model.ipynb\n","import torch\n","import torch.nn as nn\n","class SequenceModel(nn.Module):\n","    def __init__(\n","            self,\n","            input_size,\n","            output_size,\n","            hidden_size,\n","            num_layers,\n","            bidirectional,\n","            sequence_model=\"GRU\",\n","            output_activate_function=\"Tanh\"\n","    ):\n","        \"\"\"\n","       Sequence model, optional LSTM or CRN, support subband input\n","\n","        Args:\n","            input_size: Input feature size per frame\n","            output_size: Output feature size per frame\n","            hidden_size: Number of hidden units in sequence model\n","            num_layers:  Number of layers\n","            bidirectional: Whether it is two-directional\n","            sequence_model: LSTM or GRU\n","            output_activate_function: Tanh or ReLU\n","        \"\"\"\n","        super().__init__()\n","        # Sequence layer\n","        if sequence_model == \"LSTM\":\n","            self.sequence_model = nn.LSTM(\n","                input_size=input_size,\n","                hidden_size=hidden_size,\n","                num_layers=num_layers,\n","                batch_first=True,\n","                bidirectional=bidirectional,\n","            )\n","        elif sequence_model == \"GRU\":\n","            self.sequence_model = nn.GRU(\n","                input_size=input_size,\n","                hidden_size=hidden_size,\n","                num_layers=num_layers,\n","                batch_first=True,\n","                bidirectional=bidirectional,\n","            )\n","        else:\n","            raise NotImplementedError(f\"Not implemented {sequence_model}\")\n","\n","        # Fully connected layer\n","        if bidirectional:\n","            self.fc_output_layer = nn.Linear(hidden_size * 2, output_size)\n","        else:\n","            self.fc_output_layer = nn.Linear(hidden_size, output_size)\n","\n","        # Activation function layer\n","        if output_activate_function:\n","            if output_activate_function == \"Tanh\":\n","                self.activate_function = nn.Tanh()\n","            elif output_activate_function == \"ReLU\":\n","                self.activate_function = nn.ReLU()\n","            elif output_activate_function == \"ReLU6\":\n","                self.activate_function = nn.ReLU6()\n","            else:\n","                raise NotImplementedError(f\"Not implemented activation function {self.activate_function}\")\n","\n","        self.output_activate_function = output_activate_function\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x: [B, F, T]\n","        Returns:\n","            [B, F, T]\n","        \"\"\"\n","        assert x.dim() == 3\n","        self.sequence_model.flatten_parameters()\n","\n","        # Making elements contiguous in memory is conducive to model optimization, but new space is allocated\n","        # It is recommended to use it before the network starts a large number of calculations\n","        x = x.permute(0, 2, 1).contiguous()  # [B, F, T] => [B, T, F]\n","        o, _ = self.sequence_model(x)\n","        o = self.fc_output_layer(o)\n","        if self.output_activate_function:\n","            o = self.activate_function(o)\n","        o = o.permute(0, 2, 1).contiguous()  # [B, T, F] => [B, F, T]\n","        return o\n","\n","\n","# def _print_networks(nets: list):\n","#     print(f\"This project contains {len(nets)} networks, the number of the parameters: \")\n","#     params_of_all_networks = 0\n","#     for i, net in enumerate(nets, start=1):\n","#         params_of_network = 0\n","#         for param in net.parameters():\n","#             params_of_network += param.numel()\n","\n","#         print(f\"\\tNetwork {i}: {params_of_network / 1e6} million.\")\n","#         params_of_all_networks += params_of_network\n","\n","#     print(f\"The amount of parameters in the project is {params_of_all_networks / 1e6} million.\")\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLSVGxRwX2ha","executionInfo":{"status":"ok","timestamp":1628071333447,"user_tz":-270,"elapsed":613,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["class Model(BaseModel):\n","    def __init__(\n","            self,\n","            num_freqs,\n","            hidden_size,\n","            sequence_model,\n","            output_activate_function,\n","            look_ahead,\n","            norm_type=\"offline_laplace_norm\",\n","            weight_init=True,\n","    ):\n","        \"\"\"\n","        Fullband Model (cIRM mask)\n","\n","        Args:\n","            num_freqs:\n","            hidden_size:\n","            sequence_model:\n","            output_activate_function:\n","            look_ahead:\n","        \"\"\"\n","        super().__init__()\n","        self.fullband_model = SequenceModel(\n","            input_size=num_freqs,\n","            output_size=num_freqs * 2,\n","            hidden_size=hidden_size,\n","            num_layers=3,\n","            bidirectional=False,\n","            sequence_model=sequence_model,\n","            output_activate_function=output_activate_function\n","        )\n","\n","        self.look_ahead = look_ahead\n","        self.norm = self.norm_wrapper(norm_type)\n","        if weight_init:\n","            print(\"Initializing model...\")\n","            self.apply(self.weight_init)\n","\n","    def forward(self, noisy_mag):\n","        \"\"\"\n","        Args:\n","            noisy_mag: [B, 1, F, T], noisy magnitude spectrogram\n","\n","        Returns:\n","            [B, 2, F, T], the real part and imag part of the enhanced spectrogram\n","        \"\"\"\n","        assert noisy_mag.dim() == 4\n","\n","        noisy_mag = functional.pad(noisy_mag, [0, self.look_ahead])  # Pad look ahead\n","        batch_size, num_channels, num_freqs, num_frames = noisy_mag.size()\n","        assert num_channels == 1, f\"{self.__class__.__name__} takes the mag feature as inputs.\"\n","\n","        noisy_mag = self.norm(noisy_mag).reshape(batch_size, num_channels * num_freqs, num_frames)\n","        output = self.fullband_model(noisy_mag).reshape(batch_size, 2, num_freqs, num_frames)\n","\n","        return output[:, :, :, self.look_ahead:]\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"IxW5WnjVX3x1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628071341738,"user_tz":-270,"elapsed":1494,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}},"outputId":"328749b4-f3e9-4369-f051-1f3f2c9232e3"},"source":["if __name__ == \"__main__\":\n","    import datetime\n","\n","    with torch.no_grad():\n","        ipt = torch.rand(1, 1, 161, 100)\n","        model = Model(\n","            num_freqs=161,\n","            look_ahead=1,\n","            sequence_model=\"LSTM\",\n","            output_activate_function=None,\n","            hidden_size=512,\n","        )\n","\n","        a = datetime.datetime.now()\n","        print(model(ipt).min())\n","        print(model(ipt).shape)\n","        b = datetime.datetime.now()\n","        print(f\"{b - a}\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Initializing model...\n","tensor(-3.2527)\n","torch.Size([1, 2, 161, 100])\n","0:00:00.309261\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AKt0D7RdnSaJ"},"source":[""],"execution_count":null,"outputs":[]}]}