{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trainer1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODtjg599YKxAyjoXay5dKb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XfzW3AyWW5VD","executionInfo":{"status":"ok","timestamp":1628108269806,"user_tz":-270,"elapsed":846,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}},"outputId":"37f15828-4695-4820-b8c1-5f308865d638"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","% cd gdrive/MyDrive/'Colab Notebooks'/FullSubNet\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","[Errno 2] No such file or directory: 'gdrive/MyDrive/Colab Notebooks/FullSubNet'\n","/content/gdrive/MyDrive/Colab Notebooks/FullSubNet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sy1MP8omiHeo","executionInfo":{"status":"ok","timestamp":1628108273817,"user_tz":-270,"elapsed":1182,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["import matplotlib.pyplot as plt\n","import torch\n","from torch.cuda.amp import autocast\n","from tqdm import tqdm\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhlfn-sFiDmv"},"source":["\n","# from audio_zen.trainer.base_trainer import BaseTrainer\n","# from audio_zen.acoustics.mask import build_complex_ideal_ratio_mask, decompress_cIRM\n","# from audio_zen.acoustics.feature import mag_phase"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qDfzKa2XGh7","executionInfo":{"status":"ok","timestamp":1628109684226,"user_tz":-270,"elapsed":798,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["plt.switch_backend('agg')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnrQ-7UCjI8G","executionInfo":{"status":"ok","timestamp":1628109684950,"user_tz":-270,"elapsed":4,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["def build_complex_ideal_ratio_mask(noisy: torch.complex64, clean: torch.complex64) -> torch.Tensor:\n","    \"\"\"\n","\n","    Args:\n","        noisy: [B, F, T], noisy complex-valued stft coefficients\n","        clean: [B, F, T], clean complex-valued stft coefficients\n","\n","    Returns:\n","        [B, F, T, 2]\n","    \"\"\"\n","    denominator = torch.square(noisy.real) + torch.square(noisy.imag) + EPSILON\n","\n","    mask_real = (noisy.real * clean.real + noisy.imag * clean.imag) / denominator\n","    mask_imag = (noisy.real * clean.imag - noisy.imag * clean.real) / denominator\n","\n","    complex_ratio_mask = torch.stack((mask_real, mask_imag), dim=-1)\n","\n","    return compress_cIRM(complex_ratio_mask, K=10, C=0.1)\n","\n","\n","def compress_cIRM(mask, K=10, C=0.1):\n","    \"\"\"\n","        Compress from (-inf, +inf) to [-K ~ K]\n","    \"\"\"\n","    if torch.is_tensor(mask):\n","        mask = -100 * (mask <= -100) + mask * (mask > -100)\n","        mask = K * (1 - torch.exp(-C * mask)) / (1 + torch.exp(-C * mask))\n","    else:\n","        mask = -100 * (mask <= -100) + mask * (mask > -100)\n","        mask = K * (1 - np.exp(-C * mask)) / (1 + np.exp(-C * mask))\n","    return mask\n","\n","\n","def decompress_cIRM(mask, K=10, limit=9.9):\n","    mask = limit * (mask >= limit) - limit * (mask <= -limit) + mask * (torch.abs(mask) < limit)\n","    mask = -K * torch.log((K - mask) / (K + mask))\n","    return mask\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDHeCAAJ05O3","executionInfo":{"status":"ok","timestamp":1628109687670,"user_tz":-270,"elapsed":360,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["def mag_phase(complex_tensor):\n","    return torch.abs(complex_tensor), torch.angle(complex_tensor)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UoIFTKv4iqb8"},"source":["### base_trainer"]},{"cell_type":"code","metadata":{"id":"Yo953AeiivAz","executionInfo":{"status":"ok","timestamp":1628109693060,"user_tz":-270,"elapsed":1244,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["#base_trainer.ipynb\n","class BaseTrainer:\n","    def __init__(self, dist, rank, config, resume, only_validation, model, loss_function, optimizer):\n","        torch.cuda.set_device(rank)\n","        self.model = DistributedDataParallel(model.cuda(rank), device_ids=[rank])\n","        self.optimizer = optimizer\n","        self.loss_function = loss_function\n","\n","        # DistributedDataParallel (DDP)\n","        self.rank = rank\n","        self.dist = dist\n","\n","        #It may be due to K80 or cuda problems.\n","        torch.backends.cudnn.enabled = config[\"meta\"][\"cudnn_enable\"]\n","        # torch.backends.cudnn.deterministic = True\n","        # torch.backends.cudnn.benchmark = False\n","\n","        # Automatic mixed precision (AMP)\n","        self.use_amp = config[\"meta\"][\"use_amp\"]\n","        self.scaler = GradScaler(enabled=self.use_amp)\n","\n","        # Acoustics\n","        self.acoustic_config = config[\"acoustics\"]\n","        n_fft = self.acoustic_config[\"n_fft\"]\n","        hop_length = self.acoustic_config[\"hop_length\"]\n","        win_length = self.acoustic_config[\"win_length\"]\n","\n","        # Supported STFT\n","        self.torch_stft = partial(stft, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n","        self.torch_istft = partial(istft, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n","        self.librosa_stft = partial(librosa.stft, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n","        self.librosa_istft = partial(librosa.istft, hop_length=hop_length, win_length=win_length)\n","\n","        # Trainer.train in the config\n","        self.train_config = config[\"trainer\"][\"train\"]\n","        self.epochs = self.train_config[\"epochs\"]\n","        self.save_checkpoint_interval = self.train_config[\"save_checkpoint_interval\"]\n","        self.clip_grad_norm_value = self.train_config[\"clip_grad_norm_value\"]\n","        assert self.save_checkpoint_interval >= 1, \"Check the 'save_checkpoint_interval' parameter in the config. It should be large than one.\"\n","\n","        # Trainer.validation in the config\n","        self.validation_config = config[\"trainer\"][\"validation\"]\n","        self.validation_interval = self.validation_config[\"validation_interval\"]\n","        self.save_max_metric_score = self.validation_config[\"save_max_metric_score\"]\n","        assert self.validation_interval >= 1, \"Check the 'validation_interval' parameter in the config. It should be large than one.\"\n","\n","        # Trainer.visualization in the config\n","        self.visualization_config = config[\"trainer\"][\"visualization\"]\n","\n","        # In the 'train.py' file, if the 'resume' item is 'True', we will update the following args:\n","        self.start_epoch = 1\n","        self.best_score = -np.inf if self.save_max_metric_score else np.inf\n","        self.save_dir = Path(config[\"meta\"][\"save_dir\"]).expanduser().absolute() / config[\"meta\"][\"experiment_name\"]\n","        self.checkpoints_dir = self.save_dir / \"checkpoints\"\n","        self.logs_dir = self.save_dir / \"logs\"\n","\n","        if resume:\n","            self._resume_checkpoint()\n","\n","        # Debug validation, which skips training\n","        self.only_validation = only_validation\n","\n","        if config[\"meta\"][\"preloaded_model_path\"]:\n","            self._preload_model(Path(config[\"meta\"][\"preloaded_model_path\"]))\n","\n","        if self.rank == 0:\n","            prepare_empty_dir([self.checkpoints_dir, self.logs_dir], resume=resume)\n","\n","            self.writer = SummaryWriter(self.logs_dir.as_posix(), max_queue=5, flush_secs=30)\n","            self.writer.add_text(\n","                tag=\"Configuration\",\n","                text_string=f\"<pre>  \\n{toml.dumps(config)}  \\n</pre>\",\n","                global_step=1\n","            )\n","\n","            print(\"The configurations are as follows: \")\n","            print(config)  # except \"\\n\"\n","\n","            with open((self.save_dir / f\"{time.strftime('%Y-%m-%d %H:%M:%S')}.toml\").as_posix(), \"w\") as handle:\n","                toml.dump(config, handle)\n","\n","            self._print_networks([self.model])\n","\n","    def _preload_model(self, model_path):\n","        \"\"\"\n","        Preload model parameters (in \"*.tar\" format) at the start of experiment.\n","\n","        Args:\n","            model_path (Path): The file path of the *.tar file\n","        \"\"\"\n","        model_path = model_path.expanduser().absolute()\n","        assert model_path.exists(), f\"The file {model_path.as_posix()} is not exist. please check path.\"\n","\n","        model_checkpoint = torch.load(model_path.as_posix(), map_location=\"cpu\")\n","        self.model.load_state_dict(model_checkpoint[\"model\"], strict=False)\n","        self.model.to(self.rank)\n","\n","        if self.rank == 0:\n","            print(f\"Model preloaded successfully from {model_path.as_posix()}.\")\n","\n","    def _resume_checkpoint(self):\n","        \"\"\"\n","        Resume the experiment from the latest checkpoint.\n","        \"\"\"\n","        latest_model_path = self.checkpoints_dir.expanduser().absolute() / \"latest_model.tar\"\n","        assert latest_model_path.exists(), f\"{latest_model_path} does not exist, can not load latest checkpoint.\"\n","\n","        # Load it on the CPU and later use .to(device) on the model\n","        # Maybe slightly slow than use map_location=\"cuda:<...>\"\n","        # https://stackoverflow.com/questions/61642619/pytorch-distributed-data-parallel-confusion\n","        checkpoint = torch.load(latest_model_path.as_posix(), map_location=\"cpu\")\n","\n","        # Make sure all processes (GPUs) do not start loading before the saving is finished.\n","        # see https://stackoverflow.com/questions/59760328/how-does-torch-distributed-barrier-work\n","        self.dist.barrier()\n","\n","        self.start_epoch = checkpoint[\"epoch\"] + 1\n","        self.best_score = checkpoint[\"best_score\"]\n","        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","        self.scaler.load_state_dict(checkpoint[\"scaler\"])\n","\n","        if isinstance(self.model, torch.nn.parallel.DistributedDataParallel):\n","            self.model.module.load_state_dict(checkpoint[\"model\"])\n","        else:\n","            self.model.load_state_dict(checkpoint[\"model\"])\n","\n","        # self.model.to(self.rank)\n","\n","        if self.rank == 0:\n","            print(f\"Model checkpoint loaded. Training will begin at {self.start_epoch} epoch.\")\n","\n","    def _save_checkpoint(self, epoch, is_best_epoch=False):\n","        \"\"\"\n","        Save checkpoint to \"<save_dir>/<config name>/checkpoints\" directory, which consists of:\n","            - epoch\n","            - best metric score in historical epochs\n","            - optimizer parameters\n","            - model parameters\n","\n","        Args:\n","            is_best_epoch (bool): In the current epoch, if the model get a best metric score (is_best_epoch=True),\n","                                the checkpoint of model will be saved as \"<save_dir>/checkpoints/best_model.tar\".\n","        \"\"\"\n","        print(f\"\\t Saving {epoch} epoch model checkpoint...\")\n","\n","        state_dict = {\n","            \"epoch\": epoch,\n","            \"best_score\": self.best_score,\n","            \"optimizer\": self.optimizer.state_dict(),\n","            \"scaler\": self.scaler.state_dict()\n","        }\n","\n","        if isinstance(self.model, torch.nn.parallel.DistributedDataParallel):\n","            state_dict[\"model\"] = self.model.module.state_dict()\n","        else:\n","            state_dict[\"model\"] = self.model.state_dict()\n","\n","        # Saved in \"latest_model.tar\"\n","        # Contains all checkpoint information, including the optimizer parameters, the model parameters, etc.\n","        # New checkpoint will overwrite the older one.\n","        torch.save(state_dict, (self.checkpoints_dir / \"latest_model.tar\").as_posix())\n","\n","        # \"model_{epoch_number}.pth\"\n","        # Contains only model.\n","        torch.save(state_dict[\"model\"], (self.checkpoints_dir / f\"model_{str(epoch).zfill(4)}.pth\").as_posix())\n","\n","        # If the model get a best metric score (means \"is_best_epoch=True\") in the current epoch,\n","        # the model checkpoint will be saved as \"best_model.tar\"\n","        # The newer best-scored checkpoint will overwrite the older one.\n","        if is_best_epoch:\n","            print(f\"\\t :smiley: Found a best score in the {epoch} epoch, saving...\")\n","            torch.save(state_dict, (self.checkpoints_dir / \"best_model.tar\").as_posix())\n","\n","    def _is_best_epoch(self, score, save_max_metric_score=True):\n","        \"\"\"\n","        Check if the current model got the best metric score\n","        \"\"\"\n","        if save_max_metric_score and score >= self.best_score:\n","            self.best_score = score\n","            return True\n","        elif not save_max_metric_score and score <= self.best_score:\n","            self.best_score = score\n","            return True\n","        else:\n","            return False\n","\n","    @staticmethod\n","    def _print_networks(models: list):\n","        print(f\"This project contains {len(models)} models, the number of the parameters is: \")\n","\n","        params_of_all_networks = 0\n","        for idx, model in enumerate(models, start=1):\n","            params_of_network = 0\n","            for param in model.parameters():\n","                params_of_network += param.numel()\n","\n","            print(f\"\\tNetwork {idx}: {params_of_network / 1e6} million.\")\n","            params_of_all_networks += params_of_network\n","\n","        print(f\"The amount of parameters in the project is {params_of_all_networks / 1e6} million.\")\n","\n","    def _set_models_to_train_mode(self):\n","        self.model.train()\n","\n","    def _set_models_to_eval_mode(self):\n","        self.model.eval()\n","\n","    def spec_audio_visualization(self, noisy, enhanced, clean, name, epoch, mark=\"\"):\n","        self.writer.add_audio(f\"{mark}_Speech/{name}_Noisy\", noisy, epoch, sample_rate=16000)\n","        self.writer.add_audio(f\"{mark}_Speech/{name}_Enhanced\", enhanced, epoch, sample_rate=16000)\n","        self.writer.add_audio(f\"{mark}_Speech/{name}_Clean\", clean, epoch, sample_rate=16000)\n","\n","        # Visualize the spectrogram of noisy speech, clean speech, and enhanced speech\n","        noisy_mag, _ = librosa.magphase(self.librosa_stft(noisy, n_fft=320, hop_length=160, win_length=320))\n","        enhanced_mag, _ = librosa.magphase(self.librosa_stft(enhanced, n_fft=320, hop_length=160, win_length=320))\n","        clean_mag, _ = librosa.magphase(self.librosa_stft(clean, n_fft=320, hop_length=160, win_length=320))\n","        fig, axes = plt.subplots(3, 1, figsize=(6, 6))\n","        for k, mag in enumerate([noisy_mag, enhanced_mag, clean_mag]):\n","            axes[k].set_title(\n","                f\"mean: {np.mean(mag):.3f}, \"\n","                f\"std: {np.std(mag):.3f}, \"\n","                f\"max: {np.max(mag):.3f}, \"\n","                f\"min: {np.min(mag):.3f}\"\n","            )\n","            librosa.display.specshow(librosa.amplitude_to_db(mag), cmap=\"magma\", y_axis=\"linear\", ax=axes[k], sr=16000)\n","        plt.tight_layout()\n","        self.writer.add_figure(f\"{mark}_Spectrogram/{name}\", fig, epoch)\n","\n","    def metrics_visualization(self, noisy_list, clean_list, enhanced_list, metrics_list, epoch, num_workers=10,\n","                              mark=\"\"):\n","        \"\"\"\n","        Get metrics on validation dataset by paralleling.\n","\n","        Notes:\n","            1. You can register other metrics, but STOI and WB_PESQ metrics must be existence. These two metrics are\n","             used for checking if the current epoch is a \"best epoch.\"\n","            2. If you want to use a new metric, you must register it in \"util.metrics\" file.\n","        \"\"\"\n","        assert \"STOI\" in metrics_list and \"WB_PESQ\" in metrics_list, \"'STOI' and 'WB_PESQ' must be exist.\"\n","\n","        # Check if the metric is registered in \"util.metrics\" file.\n","        for i in metrics_list:\n","            assert i in metrics.REGISTERED_METRICS.keys(), f\"{i} is not registered, please check 'util.metrics' file.\"\n","\n","        stoi_mean = 0.0\n","        wb_pesq_mean = 0.0\n","        for metric_name in metrics_list:\n","            score_on_noisy = Parallel(n_jobs=num_workers)(\n","                delayed(metrics.REGISTERED_METRICS[metric_name])(ref, est) for ref, est in zip(clean_list, noisy_list)\n","            )\n","            score_on_enhanced = Parallel(n_jobs=num_workers)(\n","                delayed(metrics.REGISTERED_METRICS[metric_name])(ref, est) for ref, est in\n","                zip(clean_list, enhanced_list)\n","            )\n","\n","            # Add mean value of the metric to tensorboard\n","            mean_score_on_noisy = np.mean(score_on_noisy)\n","            mean_score_on_enhanced = np.mean(score_on_enhanced)\n","            self.writer.add_scalars(f\"{mark}_Validation/{metric_name}\", {\n","                \"Noisy\": mean_score_on_noisy,\n","                \"Enhanced\": mean_score_on_enhanced\n","            }, epoch)\n","\n","            if metric_name == \"STOI\":\n","                stoi_mean = mean_score_on_enhanced\n","\n","            if metric_name == \"WB_PESQ\":\n","                wb_pesq_mean = transform_pesq_range(mean_score_on_enhanced)\n","\n","        return (stoi_mean + wb_pesq_mean) / 2\n","\n","    def train(self):\n","        for epoch in range(self.start_epoch, self.epochs + 1):\n","            if self.rank == 0:\n","                print(f\"{'=' * 15} {epoch} epoch {'=' * 15}\")\n","                print(\"[0 seconds] Begin training...\")\n","\n","            # [debug validation] Only run validation (only use the first GPU (process))\n","            # inference + calculating metrics + saving checkpoints\n","            if self.only_validation and self.rank == 0:\n","                self._set_models_to_eval_mode()\n","                metric_score = self._validation_epoch(epoch)\n","\n","                if self._is_best_epoch(metric_score, save_max_metric_score=self.save_max_metric_score):\n","                    self._save_checkpoint(epoch, is_best_epoch=True)\n","\n","                # Skip the following regular training, saving checkpoints, and validation\n","                continue\n","\n","            # Regular training\n","            timer = ExecutionTime()\n","            self._set_models_to_train_mode()\n","            self._train_epoch(epoch)\n","\n","            #  Regular save checkpoints\n","            if self.rank == 0 and self.save_checkpoint_interval != 0 and (epoch % self.save_checkpoint_interval == 0):\n","                self._save_checkpoint(epoch)\n","\n","            # Regular validation\n","            if self.rank == 0 and (epoch % self.validation_interval == 0):\n","                print(f\"[{timer.duration()} seconds] Training has finished, validation is in progress...\")\n","\n","                self._set_models_to_eval_mode()\n","                metric_score = self._validation_epoch(epoch)\n","\n","                if self._is_best_epoch(metric_score, save_max_metric_score=self.save_max_metric_score):\n","                    self._save_checkpoint(epoch, is_best_epoch=True)\n","\n","            if self.rank == 0:\n","                print(f\"[{timer.duration()} seconds] This epoch is finished.\")\n","\n","    def _train_epoch(self, epoch):\n","        raise NotImplementedError\n","\n","    def _validation_epoch(self, epoch):\n","        raise NotImplementedError\n","\n","\n","\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcG5JO8fXHXd","executionInfo":{"status":"ok","timestamp":1628109696597,"user_tz":-270,"elapsed":832,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}}},"source":["\n","class Trainer(BaseTrainer):\n","    def __init__(self, dist, rank, config, resume, only_validation, model, loss_function, optimizer, train_dataloader, validation_dataloader):\n","        super().__init__(dist, rank, config, resume, only_validation, model, loss_function, optimizer)\n","        self.train_dataloader = train_dataloader\n","        self.valid_dataloader = validation_dataloader\n","\n","    def _train_epoch(self, epoch):\n","        loss_total = 0.0\n","\n","        for noisy, clean in tqdm(self.train_dataloader, desc=f\"Training {self.rank}\"):\n","            self.optimizer.zero_grad()\n","\n","            noisy = noisy.to(self.rank)\n","            clean = clean.to(self.rank)\n","\n","            noisy_complex = self.torch_stft(noisy)\n","            clean_complex = self.torch_stft(clean)\n","\n","            noisy_mag, _ = mag_phase(noisy_complex)\n","            cIRM = build_complex_ideal_ratio_mask(noisy_complex, clean_complex)  # [B, F, T, 2]\n","\n","            with autocast(enabled=self.use_amp):\n","                # [B, F, T] => [B, 1, F, T] => model => [B, 2, F, T] => [B, F, T, 2]\n","                noisy_mag = noisy_mag.unsqueeze(1)\n","                cRM = self.model(noisy_mag)\n","                cRM = cRM.permute(0, 2, 3, 1)\n","                loss = self.loss_function(cIRM, cRM)\n","\n","            self.scaler.scale(loss).backward()\n","            self.scaler.unscale_(self.optimizer)\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_grad_norm_value)\n","            self.scaler.step(self.optimizer)\n","            self.scaler.update()\n","\n","            loss_total += loss.item()\n","\n","        if self.rank == 0:\n","            self.writer.add_scalar(f\"Loss/Train\", loss_total / len(self.train_dataloader), epoch)\n","\n","    @torch.no_grad()\n","    def _validation_epoch(self, epoch):\n","        visualization_n_samples = self.visualization_config[\"n_samples\"]\n","        visualization_num_workers = self.visualization_config[\"num_workers\"]\n","        visualization_metrics = self.visualization_config[\"metrics\"]\n","\n","        loss_total = 0.0\n","        loss_list = {\"With_reverb\": 0.0, \"No_reverb\": 0.0, }\n","        item_idx_list = {\"With_reverb\": 0, \"No_reverb\": 0, }\n","        noisy_y_list = {\"With_reverb\": [], \"No_reverb\": [], }\n","        clean_y_list = {\"With_reverb\": [], \"No_reverb\": [], }\n","        enhanced_y_list = {\"With_reverb\": [], \"No_reverb\": [], }\n","        validation_score_list = {\"With_reverb\": 0.0, \"No_reverb\": 0.0}\n","\n","        # speech_type in (\"with_reverb\", \"no_reverb\")\n","        for i, (noisy, clean, name, speech_type) in tqdm(enumerate(self.valid_dataloader), desc=\"Validation\"):\n","            assert len(name) == 1, \"The batch size for the validation stage must be one.\"\n","            name = name[0]\n","            speech_type = speech_type[0]\n","\n","            noisy = noisy.to(self.rank)\n","            clean = clean.to(self.rank)\n","\n","            noisy_complex = self.torch_stft(noisy)\n","            clean_complex = self.torch_stft(clean)\n","\n","            noisy_mag, _ = mag_phase(noisy_complex)\n","            cIRM = build_complex_ideal_ratio_mask(noisy_complex, clean_complex)  # [B, F, T, 2]\n","\n","            noisy_mag = noisy_mag.unsqueeze(1)\n","            cRM = self.model(noisy_mag)\n","            cRM = cRM.permute(0, 2, 3, 1)\n","\n","            loss = self.loss_function(cIRM, cRM)\n","\n","            cRM = decompress_cIRM(cRM)\n","\n","            enhanced_real = cRM[..., 0] * noisy_complex.real - cRM[..., 1] * noisy_complex.imag\n","            enhanced_imag = cRM[..., 1] * noisy_complex.real + cRM[..., 0] * noisy_complex.imag\n","            enhanced_complex = torch.stack((enhanced_real, enhanced_imag), dim=-1)\n","            enhanced = self.torch_istft(enhanced_complex, length=noisy.size(-1))\n","\n","            noisy = noisy.detach().squeeze(0).cpu().numpy()\n","            clean = clean.detach().squeeze(0).cpu().numpy()\n","            enhanced = enhanced.detach().squeeze(0).cpu().numpy()\n","\n","            assert len(noisy) == len(clean) == len(enhanced)\n","            loss_total += loss\n","\n","            # Separated loss\n","            loss_list[speech_type] += loss\n","            item_idx_list[speech_type] += 1\n","\n","            if item_idx_list[speech_type] <= visualization_n_samples:\n","                self.spec_audio_visualization(noisy, enhanced, clean, name, epoch, mark=speech_type)\n","\n","            noisy_y_list[speech_type].append(noisy)\n","            clean_y_list[speech_type].append(clean)\n","            enhanced_y_list[speech_type].append(enhanced)\n","\n","        self.writer.add_scalar(f\"Loss/Validation_Total\", loss_total / len(self.valid_dataloader), epoch)\n","\n","        for speech_type in (\"With_reverb\", \"No_reverb\"):\n","            self.writer.add_scalar(f\"Loss/{speech_type}\", loss_list[speech_type] / len(self.valid_dataloader), epoch)\n","\n","            validation_score_list[speech_type] = self.metrics_visualization(\n","                noisy_y_list[speech_type], clean_y_list[speech_type], enhanced_y_list[speech_type],\n","                visualization_metrics, epoch, visualization_num_workers, mark=speech_type\n","            )\n","\n","        return validation_score_list[\"No_reverb\"]\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSO0xusV5md6"},"source":[""],"execution_count":null,"outputs":[]}]}