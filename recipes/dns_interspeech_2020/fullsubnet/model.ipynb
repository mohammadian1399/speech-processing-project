{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1d2_JXpTU4jLmU-Kf0xYvVOTlyAfuwXaG","authorship_tag":"ABX9TyNUtIPpoWX1WAv7oZcJG8u6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfSHPFOhV7Vb","executionInfo":{"status":"ok","timestamp":1628201621095,"user_tz":-270,"elapsed":53641,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}},"outputId":"3b9dbb54-b33f-447f-ee14-db5ba8b4a2b5"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","% cd gdrive/MyDrive/'Colab Notebooks'/FullSubNet\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/Colab Notebooks/FullSubNet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HZEgX4tNoTmF"},"source":["import torch\n","from torch.nn import functional"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M207mF37_S03"},"source":["# import sys\n","# sys.path.insert(0,'/content/drive/My Drive/ColabNotebooks/FullSubNet/ audio_zen')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GZ1mP-D-Gh3k"},"source":["# from audio_zen.acoustics.feature import drop_band\n","# from audio_zen.model.base_model import BaseModel\n","# from audio_zen.model.module.sequence_model import SequenceModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAE1fipi7hHf"},"source":["def drop_band(input, num_groups=2):\n","    \"\"\"\n","    Reduce computational complexity of the sub-band part in the FullSubNet model.\n","\n","    Shapes:\n","        input: [B, C, F, T]\n","        return: [B, C, F // num_groups, T]\n","    \"\"\"\n","    batch_size, _, num_freqs, _ = input.shape\n","    assert batch_size > num_groups, f\"Batch size = {batch_size}, num_groups = {num_groups}. The batch size should larger than the num_groups.\"\n","\n","    if num_groups <= 1:\n","        # No demand for grouping\n","        return input\n","\n","    # Each sample must has the same number of the frequencies for parallel training.\n","    # Therefore, we need to drop those remaining frequencies in the high frequency part.\n","    if num_freqs % num_groups != 0:\n","        input = input[..., :(num_freqs - (num_freqs % num_groups)), :]\n","        num_freqs = input.shape[2]\n","\n","    output = []\n","    for group_idx in range(num_groups):\n","        samples_indices = torch.arange(group_idx, batch_size, num_groups, device=input.device)\n","        freqs_indices = torch.arange(group_idx, num_freqs, num_groups, device=input.device)\n","\n","        selected_samples = torch.index_select(input, dim=0, index=samples_indices)\n","        selected = torch.index_select(selected_samples, dim=2, index=freqs_indices)  # [B, C, F // num_groups, T]\n","\n","        output.append(selected)\n","\n","    return torch.cat(output, dim=0)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"asyc2YsEqahv"},"source":["### base_model"]},{"cell_type":"code","metadata":{"id":"uGWjb4yi9HAd"},"source":["import torch.nn as nn\n","import torch.nn.init as init\n","import numpy as np\n","EPSILON = np.finfo(np.float32).eps\n","class BaseModel(nn.Module):\n","    def __init__(self):\n","        super(BaseModel, self).__init__()\n","\n","    @staticmethod\n","    def unfold(input, num_neighbor):\n","        \"\"\"\n","        Along with the frequency dim, split overlapped sub band units from spectrogram.\n","\n","        Args:\n","            input: [B, C, F, T]\n","            num_neighbor:\n","\n","        Returns:\n","            [B, N, C, F_s, T], F is the size of the frequency axis of the sub-band, e.g. [2, 161, 1, 19, 200]\n","        \"\"\"\n","        assert input.dim() == 4, f\"The dim of input is {input.dim()}. It should be four dim.\"\n","        batch_size, num_channels, num_freqs, num_frames = input.size()\n","\n","        if num_neighbor < 1:\n","            # No change for the input\n","            return input.permute(0, 2, 1, 3).reshape(batch_size, num_freqs, num_channels, 1, num_frames)\n","\n","        output = input.reshape(batch_size * num_channels, 1, num_freqs, num_frames)\n","        sub_band_unit_size = num_neighbor * 2 + 1\n","\n","        # Pad to the top and bottom\n","        output = functional.pad(output, [0, 0, num_neighbor, num_neighbor], mode=\"reflect\")\n","\n","        output = functional.unfold(output, (sub_band_unit_size, num_frames))\n","        assert output.shape[-1] == num_freqs, f\"n_freqs != N (sub_band), {num_freqs} != {output.shape[-1]}\"\n","\n","        # Split the dim of the unfolded feature\n","        output = output.reshape(batch_size, num_channels, sub_band_unit_size, num_frames, num_freqs)\n","        output = output.permute(0, 4, 1, 2, 3).contiguous()\n","\n","        return output\n","\n","    @staticmethod\n","    def _reduce_complexity_separately(sub_band_input, full_band_output, device):\n","        \"\"\"\n","\n","        Args:\n","            sub_band_input: [60, 257, 1, 33, 200]\n","            full_band_output: [60, 257, 1, 3, 200]\n","            device:\n","\n","        Notes:\n","            1. 255 and 256 freq not able to be trained\n","            2. batch size should be divisible by 3, otherwise the frequency in the last part of the batch will not be well trained\n","\n","        Returns:\n","            [60, 85, 1, 36, 200]\n","        \"\"\"\n","        batch_size = full_band_output.shape[0]\n","        n_freqs = full_band_output.shape[1]\n","        sub_batch_size = batch_size // 3\n","        final_selected = []\n","\n","        for idx in range(3):\n","            # [0, 60) => [0, 20)\n","            sub_batch_indices = torch.arange(idx * sub_batch_size, (idx + 1) * sub_batch_size, device=device)\n","            full_band_output_sub_batch = torch.index_select(full_band_output, dim=0, index=sub_batch_indices)\n","            sub_band_output_sub_batch = torch.index_select(sub_band_input, dim=0, index=sub_batch_indices)\n","\n","            # Avoid to use padded value (first freq and last freq)\n","            # i = 0, (1, 256, 3) = [1, 4, ..., 253]\n","            # i = 1, (2, 256, 3) = [2, 5, ..., 254]\n","            # i = 2, (3, 256, 3) = [3, 6, ..., 255]\n","            freq_indices = torch.arange(idx + 1, n_freqs - 1, step=3, device=device)\n","            full_band_output_sub_batch = torch.index_select(full_band_output_sub_batch, dim=1, index=freq_indices)\n","            sub_band_output_sub_batch = torch.index_select(sub_band_output_sub_batch, dim=1, index=freq_indices)\n","\n","            # ([30, 85, 1, 33 200], [30, 85, 1, 3, 200]) => [30, 85, 1, 36, 200]\n","\n","            final_selected.append(torch.cat([sub_band_output_sub_batch, full_band_output_sub_batch], dim=-2))\n","\n","        return torch.cat(final_selected, dim=0)\n","\n","    @staticmethod\n","    def sband_forgetting_norm(input, train_sample_length):\n","        \"\"\"\n","        Same as forgetting norm, but use the middle frequency band of the spliced model to calculate the mean ineffective\n","        Args:\n","            input:\n","            train_sample_length:\n","\n","        Returns:\n","\n","        \"\"\"\n","        assert input.ndim == 3\n","        batch_size, n_freqs, n_frames = input.size()\n","\n","        eps = 1e-10\n","        alpha = (train_sample_length - 1) / (train_sample_length + 1)\n","        mu = 0\n","        mu_list = []\n","\n","        for idx in range(input.shape[-1]):\n","            if idx < train_sample_length:\n","                alp = torch.min(torch.tensor([(idx - 1) / (idx + 1), alpha]))\n","                mu = alp * mu + (1 - alp) * torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","            else:\n","                mu = alpha * mu + (1 - alpha) * input[:, (n_freqs // 2 - 1), idx].reshape(batch_size, 1)\n","\n","            mu_list.append(mu)\n","\n","            # print(\"input\", input[:, :, idx].min(), input[:, :, idx].max(), input[:, :, idx].mean())\n","            # print(f\"alp {idx}: \", alp)\n","            # print(f\"mu {idx}: {mu[128, 0]}\")\n","\n","        mu = torch.stack(mu_list, dim=-1)  # [B, 1, T]\n","        input = input / (mu + eps)\n","        return input\n","\n","    @staticmethod\n","    def forgetting_norm(input, sample_length_in_training):\n","        \"\"\"\n","        The input is three-dimensional, and the mean value of the current norm is used as the mean value of the current norm by constantly estimating the mean value of the neighboring\n","\n","        Args:\n","            input: [B, F, T]\n","            sample_length_in_training: The length of training, used to calculate the smoothing factor\n","\n","        Returns:\n","\n","        \"\"\"\n","        assert input.ndim == 3\n","        batch_size, n_freqs, n_frames = input.size()\n","        eps = 1e-10\n","        mu = 0\n","        alpha = (sample_length_in_training - 1) / (sample_length_in_training + 1)\n","\n","        mu_list = []\n","        for idx in range(input.shape[-1]):\n","            if idx < sample_length_in_training:\n","                alp = torch.min(torch.tensor([(idx - 1) / (idx + 1), alpha]))\n","                mu = alp * mu + (1 - alp) * torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","            else:\n","                current_frame_mu = torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","                mu = alpha * mu + (1 - alpha) * current_frame_mu\n","\n","            mu_list.append(mu)\n","\n","            # print(\"input\", input[:, :, idx].min(), input[:, :, idx].max(), input[:, :, idx].mean())\n","            # print(f\"alp {idx}: \", alp)\n","            # print(f\"mu {idx}: {mu[128, 0]}\")\n","\n","        mu = torch.stack(mu_list, dim=-1)  # [B, 1, T]\n","        input = input / (mu + eps)\n","        return input\n","\n","    @staticmethod\n","    def hybrid_norm(input, sample_length_in_training=192):\n","        \"\"\"\n","        Args:\n","            input: [B, F, T]\n","            sample_length_in_training:\n","\n","        Returns:\n","            [B, F, T]\n","        \"\"\"\n","        assert input.ndim == 3\n","        device = input.device\n","        data_type = input.dtype\n","        batch_size, n_freqs, n_frames = input.size()\n","        eps = 1e-10\n","\n","        mu = 0\n","        alpha = (sample_length_in_training - 1) / (sample_length_in_training + 1)\n","        mu_list = []\n","        for idx in range(input.shape[-1]):\n","            if idx < sample_length_in_training:\n","                alp = torch.min(torch.tensor([(idx - 1) / (idx + 1), alpha]))\n","                mu = alp * mu + (1 - alp) * torch.mean(input[:, :, idx], dim=1).reshape(batch_size, 1)  # [B, 1]\n","                mu_list.append(mu)\n","            else:\n","                break\n","        initial_mu = torch.stack(mu_list, dim=-1)  # [B, 1, T]\n","\n","        step_sum = torch.sum(input, dim=1)  # [B, T]\n","        cumulative_sum = torch.cumsum(step_sum, dim=-1)  # [B, T]\n","\n","        entry_count = torch.arange(n_freqs, n_freqs * n_frames + 1, n_freqs, dtype=data_type, device=device)\n","        entry_count = entry_count.reshape(1, n_frames)  # [1, T]\n","        entry_count = entry_count.expand_as(cumulative_sum)  # [1, T] => [B, T]\n","\n","        cum_mean = cumulative_sum / entry_count  # B, T\n","\n","        cum_mean = cum_mean.reshape(batch_size, 1, n_frames)  # [B, 1, T]\n","\n","        # print(initial_mu[0, 0, :50])\n","        # print(\"-\"*60)\n","        # print(cum_mean[0, 0, :50])\n","        cum_mean[:, :, :sample_length_in_training] = initial_mu\n","\n","        return input / (cum_mean + eps)\n","\n","    @staticmethod\n","    def offline_laplace_norm(input):\n","        \"\"\"\n","\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","            [B, C, F, T]\n","        \"\"\"\n","        # utterance-level mu\n","        mu = torch.mean(input, dim=(1, 2, 3), keepdim=True)\n","\n","        normed = input / (mu + 1e-5)\n","\n","        return normed\n","\n","    @staticmethod\n","    def cumulative_laplace_norm(input):\n","        \"\"\"\n","\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","\n","        \"\"\"\n","        batch_size, num_channels, num_freqs, num_frames = input.size()\n","        input = input.reshape(batch_size * num_channels, num_freqs, num_frames)\n","\n","        step_sum = torch.sum(input, dim=1)  # [B * C, F, T] => [B, T]\n","        cumulative_sum = torch.cumsum(step_sum, dim=-1)  # [B, T]\n","\n","        entry_count = torch.arange(\n","            num_freqs,\n","            num_freqs * num_frames + 1,\n","            num_freqs,\n","            dtype=input.dtype,\n","            device=input.device\n","        )\n","        entry_count = entry_count.reshape(1, num_frames)  # [1, T]\n","        entry_count = entry_count.expand_as(cumulative_sum)  # [1, T] => [B, T]\n","\n","        cumulative_mean = cumulative_sum / entry_count  # B, T\n","        cumulative_mean = cumulative_mean.reshape(batch_size * num_channels, 1, num_frames)\n","\n","        normed = input / (cumulative_mean + EPSILON)\n","\n","        return normed.reshape(batch_size, num_channels, num_freqs, num_frames)\n","\n","    @staticmethod\n","    def offline_gaussian_norm(input):\n","        \"\"\"\n","        Zero-Norm\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","            [B, C, F, T]\n","        \"\"\"\n","        mu = torch.mean(input, dim=(1, 2, 3), keepdim=True)\n","        std = torch.std(input, dim=(1, 2, 3), keepdim=True)\n","\n","        normed = (input - mu) / (std + 1e-5)\n","\n","        return normed\n","\n","    @staticmethod\n","    def cumulative_layer_norm(input):\n","        \"\"\"\n","        Online zero-norm\n","\n","        Args:\n","            input: [B, C, F, T]\n","\n","        Returns:\n","            [B, C, F, T]\n","        \"\"\"\n","        batch_size, num_channels, num_freqs, num_frames = input.size()\n","        input = input.reshape(batch_size * num_channels, num_freqs, num_frames)\n","\n","        step_sum = torch.sum(input, dim=1)  # [B * C, F, T] => [B, T]\n","        step_pow_sum = torch.sum(torch.square(input), dim=1)\n","\n","        cumulative_sum = torch.cumsum(step_sum, dim=-1)  # [B, T]\n","        cumulative_pow_sum = torch.cumsum(step_pow_sum, dim=-1)  # [B, T]\n","\n","        entry_count = torch.arange(\n","            num_freqs,\n","            num_freqs * num_frames + 1,\n","            num_freqs,\n","            dtype=input.dtype,\n","            device=input.device\n","        )\n","        entry_count = entry_count.reshape(1, num_frames)  # [1, T]\n","        entry_count = entry_count.expand_as(cumulative_sum)  # [1, T] => [B, T]\n","\n","        cumulative_mean = cumulative_sum / entry_count  # [B, T]\n","        cumulative_var = (cumulative_pow_sum - 2 * cumulative_mean * cumulative_sum) / entry_count + cumulative_mean.pow(2)  # [B, T]\n","        cumulative_std = torch.sqrt(cumulative_var + EPSILON)  # [B, T]\n","\n","        cumulative_mean = cumulative_mean.reshape(batch_size * num_channels, 1, num_frames)\n","        cumulative_std = cumulative_std.reshape(batch_size * num_channels, 1, num_frames)\n","\n","        normed = (input - cumulative_mean) / cumulative_std\n","\n","        return normed.reshape(batch_size, num_channels, num_freqs, num_frames)\n","\n","    def norm_wrapper(self, norm_type: str):\n","        if norm_type == \"offline_laplace_norm\":\n","            norm = self.offline_laplace_norm\n","        elif norm_type == \"cumulative_laplace_norm\":\n","            norm = self.cumulative_laplace_norm\n","        elif norm_type == \"offline_gaussian_norm\":\n","            norm = self.offline_gaussian_norm\n","        elif norm_type == \"cumulative_layer_norm\":\n","            norm = self.cumulative_layer_norm\n","        else:\n","            raise NotImplementedError(\"You must set up a type of Norm. \"\n","                                      \"e.g. offline_laplace_norm, cumulative_laplace_norm, forgetting_norm, etc.\")\n","        return norm\n","\n","    def weight_init(self, m):\n","        \"\"\"\n","        Usage:\n","            model = Model()\n","            model.apply(weight_init)\n","        \"\"\"\n","        if isinstance(m, nn.Conv1d):\n","            init.normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.Conv2d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.Conv3d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.ConvTranspose1d):\n","            init.normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.ConvTranspose2d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.ConvTranspose3d):\n","            init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                init.normal_(m.bias.data)\n","        elif isinstance(m, nn.BatchNorm1d):\n","            init.normal_(m.weight.data, mean=1, std=0.02)\n","            init.constant_(m.bias.data, 0)\n","        elif isinstance(m, nn.BatchNorm2d):\n","            init.normal_(m.weight.data, mean=1, std=0.02)\n","            init.constant_(m.bias.data, 0)\n","        elif isinstance(m, nn.BatchNorm3d):\n","            init.normal_(m.weight.data, mean=1, std=0.02)\n","            init.constant_(m.bias.data, 0)\n","        elif isinstance(m, nn.Linear):\n","            init.xavier_normal_(m.weight.data)\n","            init.normal_(m.bias.data)\n","        elif isinstance(m, nn.LSTM):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n","        elif isinstance(m, nn.LSTMCell):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n","        elif isinstance(m, nn.GRU):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n","        elif isinstance(m, nn.GRUCell):\n","            for param in m.parameters():\n","                if len(param.shape) >= 2:\n","                    init.orthogonal_(param.data)\n","                else:\n","                    init.normal_(param.data)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lejk76trr_-O"},"source":["### sequence_model"]},{"cell_type":"code","metadata":{"id":"nO4fC5eQr-79"},"source":["class SequenceModel(nn.Module):\n","    def __init__(\n","            self,\n","            input_size,\n","            output_size,\n","            hidden_size,\n","            num_layers,\n","            bidirectional,\n","            sequence_model=\"GRU\",\n","            output_activate_function=\"Tanh\"\n","    ):\n","        \"\"\"\n","       Sequence model, optional LSTM or CRN, support subband input\n","\n","        Args:\n","            input_size: Input feature size per frame\n","            output_size: Output feature size per frame\n","            hidden_size: Number of hidden units in sequence model\n","            num_layers:  Number of layers\n","            bidirectional: Whether it is two-directional\n","            sequence_model: LSTM or GRU\n","            output_activate_function: Tanh or ReLU\n","        \"\"\"\n","        super().__init__()\n","        # Sequence layer\n","        if sequence_model == \"LSTM\":\n","            self.sequence_model = nn.LSTM(\n","                input_size=input_size,\n","                hidden_size=hidden_size,\n","                num_layers=num_layers,\n","                batch_first=True,\n","                bidirectional=bidirectional,\n","            )\n","        elif sequence_model == \"GRU\":\n","            self.sequence_model = nn.GRU(\n","                input_size=input_size,\n","                hidden_size=hidden_size,\n","                num_layers=num_layers,\n","                batch_first=True,\n","                bidirectional=bidirectional,\n","            )\n","        else:\n","            raise NotImplementedError(f\"Not implemented {sequence_model}\")\n","\n","        # Fully connected layer\n","        if bidirectional:\n","            self.fc_output_layer = nn.Linear(hidden_size * 2, output_size)\n","        else:\n","            self.fc_output_layer = nn.Linear(hidden_size, output_size)\n","\n","        # Activation function layer\n","        if output_activate_function:\n","            if output_activate_function == \"Tanh\":\n","                self.activate_function = nn.Tanh()\n","            elif output_activate_function == \"ReLU\":\n","                self.activate_function = nn.ReLU()\n","            elif output_activate_function == \"ReLU6\":\n","                self.activate_function = nn.ReLU6()\n","            else:\n","                raise NotImplementedError(f\"Not implemented activation function {self.activate_function}\")\n","\n","        self.output_activate_function = output_activate_function\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x: [B, F, T]\n","        Returns:\n","            [B, F, T]\n","        \"\"\"\n","        assert x.dim() == 3\n","        self.sequence_model.flatten_parameters()\n","\n","        # Making elements contiguous in memory is conducive to model optimization, but new space is allocated\n","        # It is recommended to use it before the network starts a large number of calculations\n","        x = x.permute(0, 2, 1).contiguous()  # [B, F, T] => [B, T, F]\n","        o, _ = self.sequence_model(x)\n","        o = self.fc_output_layer(o)\n","        if self.output_activate_function:\n","            o = self.activate_function(o)\n","        o = o.permute(0, 2, 1).contiguous()  # [B, T, F] => [B, F, T]\n","        return o"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H89Ilm4iWNMZ"},"source":["class Model(BaseModel):\n","    def __init__(self,\n","                 num_freqs,\n","                 look_ahead,\n","                 sequence_model,\n","                 fb_num_neighbors,\n","                 sb_num_neighbors,\n","                 fb_output_activate_function,\n","                 sb_output_activate_function,\n","                 fb_model_hidden_size,\n","                 sb_model_hidden_size,\n","                 norm_type=\"offline_laplace_norm\",\n","                 num_groups_in_drop_band=2,\n","                 weight_init=True,\n","                 ):\n","        \"\"\"\n","        FullSubNet model (cIRM mask)\n","\n","        Args:\n","            num_freqs: Frequency dim of the input\n","            look_ahead: Number of use of the future frames\n","            fb_num_neighbors: How much neighbor frequencies at each side from fullband model's output\n","            sb_num_neighbors: How much neighbor frequencies at each side from noisy spectrogram\n","            sequence_model: Chose one sequence model as the basic model e.g., GRU, LSTM\n","            fb_output_activate_function: fullband model's activation function\n","            sb_output_activate_function: subband model's activation function\n","            norm_type: type of normalization, see more details in \"BaseModel\" class\n","        \"\"\"\n","        super().__init__()\n","        assert sequence_model in (\"GRU\", \"LSTM\"), f\"{self.__class__.__name__} only support GRU and LSTM.\"\n","\n","        self.fb_model = SequenceModel(\n","            input_size=num_freqs,\n","            output_size=num_freqs,\n","            hidden_size=fb_model_hidden_size,\n","            num_layers=2,\n","            bidirectional=False,\n","            sequence_model=sequence_model,\n","            output_activate_function=fb_output_activate_function\n","        )\n","\n","        self.sb_model = SequenceModel(\n","            input_size=(sb_num_neighbors * 2 + 1) + (fb_num_neighbors * 2 + 1),\n","            output_size=2,\n","            hidden_size=sb_model_hidden_size,\n","            num_layers=2,\n","            bidirectional=False,\n","            sequence_model=sequence_model,\n","            output_activate_function=sb_output_activate_function\n","        )\n","\n","        self.sb_num_neighbors = sb_num_neighbors\n","        self.fb_num_neighbors = fb_num_neighbors\n","        self.look_ahead = look_ahead\n","        self.norm = self.norm_wrapper(norm_type)\n","        self.num_groups_in_drop_band = num_groups_in_drop_band\n","\n","        if weight_init:\n","            self.apply(self.weight_init)\n","\n","    def forward(self, noisy_mag):\n","        \"\"\"\n","        Args:\n","            noisy_mag: noisy magnitude spectrogram\n","\n","        Returns:\n","            The real part and imag part of the enhanced spectrogram\n","\n","        Shapes:\n","            noisy_mag: [B, 1, F, T]\n","            return: [B, 2, F, T]\n","        \"\"\"\n","        assert noisy_mag.dim() == 4\n","        noisy_mag = functional.pad(noisy_mag, [0, self.look_ahead])  # Pad the look ahead\n","        batch_size, num_channels, num_freqs, num_frames = noisy_mag.size()\n","        assert num_channels == 1, f\"{self.__class__.__name__} takes the mag feature as inputs.\"\n","\n","        # Fullband model\n","        fb_input = self.norm(noisy_mag).reshape(batch_size, num_channels * num_freqs, num_frames)\n","        fb_output = self.fb_model(fb_input).reshape(batch_size, 1, num_freqs, num_frames)\n","\n","        # Unfold fullband model's output, [B, N=F, C, F_f, T]. N is the number of sub-band units\n","        fb_output_unfolded = self.unfold(fb_output, num_neighbor=self.fb_num_neighbors)\n","        fb_output_unfolded = fb_output_unfolded.reshape(batch_size, num_freqs, self.fb_num_neighbors * 2 + 1, num_frames)\n","\n","        # Unfold noisy spectrogram, [B, N=F, C, F_s, T]\n","        noisy_mag_unfolded = self.unfold(noisy_mag, num_neighbor=self.sb_num_neighbors)\n","        noisy_mag_unfolded = noisy_mag_unfolded.reshape(batch_size, num_freqs, self.sb_num_neighbors * 2 + 1, num_frames)\n","\n","        # Concatenation, [B, F, (F_s + F_f), T]\n","        sb_input = torch.cat([noisy_mag_unfolded, fb_output_unfolded], dim=2)\n","        sb_input = self.norm(sb_input)\n","\n","        # Speeding up training without significant performance degradation.\n","        # These will be updated to the paper later.\n","        if batch_size > 1:\n","            sb_input = drop_band(sb_input.permute(0, 2, 1, 3), num_groups=self.num_groups_in_drop_band)  # [B, (F_s + F_f), F//num_groups, T]\n","            num_freqs = sb_input.shape[2]\n","            sb_input = sb_input.permute(0, 2, 1, 3)  # [B, F//num_groups, (F_s + F_f), T]\n","\n","        sb_input = sb_input.reshape(\n","            batch_size * num_freqs,\n","            (self.sb_num_neighbors * 2 + 1) + (self.fb_num_neighbors * 2 + 1),\n","            num_frames\n","        )\n","\n","        # [B * F, (F_s + F_f), T] => [B * F, 2, T] => [B, F, 2, T]\n","        sb_mask = self.sb_model(sb_input)\n","        sb_mask = sb_mask.reshape(batch_size, num_freqs, 2, num_frames).permute(0, 2, 1, 3).contiguous()\n","\n","        output = sb_mask[:, :, :, self.look_ahead:]\n","        return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elylZT-BWVzN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628072631267,"user_tz":-270,"elapsed":7510,"user":{"displayName":"parisa mohammadian","photoUrl":"","userId":"14848147456095277635"}},"outputId":"4b1df427-5532-4fc8-ae40-d9f79aa7c71b"},"source":["if __name__ == \"__main__\":\n","    import datetime\n","\n","    with torch.no_grad():\n","        model = Model(\n","            sb_num_neighbors=15,\n","            fb_num_neighbors=0,\n","            num_freqs=257,\n","            look_ahead=2,\n","            sequence_model=\"LSTM\",\n","            fb_output_activate_function=\"ReLU\",\n","            sb_output_activate_function=None,\n","            fb_model_hidden_size=512,\n","            sb_model_hidden_size=384,\n","            weight_init=False,\n","            norm_type=\"offline_laplace_norm\",\n","            num_groups_in_drop_band=2,\n","        )\n","        # ipt = torch.rand(3, 800)  # 1.6s\n","        # ipt_len = ipt.shape[-1]\n","        # # 1000 frames (16s) - 5.65s (35.31%，Pure model) - 5.78s\n","        # # 500 frames (8s) - 3.05s (38.12%，Pure model) - 3.04s\n","        # # 200 frames (3.2s) - 1.19s (37.19%，Pure model) - 1.20s\n","        # # 100 frames (1.6s) - 0.62s (38.75%，Pure model) - 0.65s\n","        # start = datetime.datetime.now()\n","        #\n","        # complex_tensor = torch.stft(ipt, n_fft=512, hop_length=256)\n","        # mag = (complex_tensor.pow(2.).sum(-1) + 1e-8).pow(0.5 * 1.0).unsqueeze(1)\n","        # print(f\"STFT: {datetime.datetime.now() - start}, {mag.shape}\")\n","        #\n","        # enhanced_complex_tensor = model(mag).detach().permute(0, 2, 3, 1)\n","        # print(enhanced_complex_tensor.shape)\n","        # print(f\"Model Inference: {datetime.datetime.now() - start}\")\n","        #\n","        # enhanced = torch.istft(enhanced_complex_tensor, 512, 256, length=ipt_len)\n","        # print(f\"iSTFT: {datetime.datetime.now() - start}\")\n","        #\n","        # print(f\"{datetime.datetime.now() - start}\")\n","        ipt = torch.rand(3, 1, 257, 200)\n","        print(model(ipt).shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([3, 2, 128, 200])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rNQjJDQxcSFO"},"source":[""],"execution_count":null,"outputs":[]}]}